{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "/  AllTroughs is running.                  /\n",
      "============================================\n",
      "localhost 5432 kanjidb postgres w0lfpack\n",
      "Python version\n",
      "3.7.2 (default, Dec 29 2018, 06:19:36) \n",
      "[GCC 7.3.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=7, micro=2, releaselevel='final', serial=0)\n",
      "Welcome to Jupyter Notebook.  You are connected to the Kanji database!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sensei/jupy-notebooks/Analytics/PorterFarms/')\n",
    "print(\"============================================\")\n",
    "print(\"/  AllTroughs is running.                  /\")\n",
    "print(\"============================================\")\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import json\n",
    "import copy\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "import pandas as pd\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../analytics_secrets.ini\")\n",
    "\n",
    "_SLACK_TOKEN = config['slack']['token']\n",
    "_CHIRPSTACK_USER = config['chirpstack']['user']\n",
    "_CHIRPSTACK_PASS = config['chirpstack']['password']\n",
    "_DB_HOST  = config['kanjidb']['dbhost']\n",
    "_DB_PORT  = config['kanjidb']['dbport']\n",
    "_DB_NAME  = config['kanjidb']['dbname']\n",
    "_DB_USER  = config['kanjidb']['dbuser']\n",
    "_DB_PASS  = config['kanjidb']['dbpass']\n",
    "\n",
    "_THRESHOLD_WMA = float(config['analytics']['waterlevelmin'])\n",
    "_THRESHOLD_WMAMEAN = 638.0\n",
    "\n",
    "_LOG_DEBUG = 0\n",
    "_LOG_INFO  = 1\n",
    "_LOG_ERROR = 2\n",
    "_LOG_LEVEL = int(config['DEFAULT']['loglevel'])\n",
    "_LOG_LEVEL = _LOG_DEBUG\n",
    "def logger(level, message):\n",
    "    if level >= _LOG_LEVEL:\n",
    "      print(message)\n",
    "\n",
    "logger(_LOG_DEBUG, \"{} {} {} {} {}\".format(_DB_HOST, _DB_PORT, _DB_NAME, _DB_USER, _DB_PASS))\n",
    "\n",
    "import kanjiticketing as kt\n",
    "\n",
    "conn = kt.getKanjiDbConnection(_DB_HOST, _DB_PORT, _DB_NAME, _DB_USER, _DB_PASS)\n",
    "if conn is not None:\n",
    "  print(\"Welcome to Jupyter Notebook.  You are connected to the Kanji database!\")\n",
    "else:\n",
    "  print(\"You are not connected to the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy**\n",
    "Determine the most likely condition at the mote:\n",
    "\n",
    "The sensor is WET, DRY, or BAD\n",
    "\n",
    "**FALSE POSITIVES: (WET INDICATION)**\n",
    "\n",
    "If the sensor emitter fails to produce IR or if the sensor phototransistor fails OPEN\n",
    "\n",
    "**FALSE NEGATIVES: (DRY INDICATION)**\n",
    "\n",
    "If the sensor phototransistor fails SHORT\n",
    "\n",
    "The secret recipe to protect against false indications consists of two things. 1) that we cycle the IR emitter at 50% duty factor. In each half-cycle the voltage at the phototransistor collector is sampled.  This process is repeated for a number of cycles (e.g. 10).  Then the mean and standard deviation are calculated.  It is the standard deviation which helps us to establish that the sensor is operating properly. 2) attached near the face of the emitter is an optically reflective surface.  The purpose of this surface is to reflect some of the IR that escapes from the sensor when it is immersed in fluid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time is 2020-06-05 20:06:40.299147+00:00\n",
      "Query timestamp will start at 2020-06-05 19:46:40.299147+00:00\n",
      "number of trough nodes 1\n",
      "\n",
      "AllTroughs processing for node agMote-20002\n",
      "SELECT dval, eval FROM kanji_eventlog WHERE node_id=20002 AND sensortype_id=39 AND timestamp > '2020-06-05 19:46:40.299147+00:00' ORDER BY timestamp desc;\n",
      "samplesize 4\n",
      "793.0 229.2\n",
      "793.0 228.7\n",
      "794.0 227.3\n",
      "794.0 228.2\n",
      "wmaMean=793.3 wmaSd=228.57\n",
      "WATER LEVEL OK. wmaMean=793.30 wmaSd=228.57\n",
      "No ticketable events for node agMote-20002\n"
     ]
    }
   ],
   "source": [
    "_MINIMUM_SD = 150\n",
    "_MINIMUM_MEAN = 400\n",
    "_MAXIMUM_MEAN = 900\n",
    "\n",
    "_CATTLE_TROUGH_MONITOR = 10004\n",
    "_AVERAGING_INTERVAL_MINUTES = 20\n",
    "_AGE_THRESHOLD_SECONDS = 900\n",
    "\n",
    "#Ticket Types\n",
    "LOW_WATER_LEVEL = 10001\n",
    "BAD_FLUIDLEVEL_SENSOR = 10005\n",
    "\n",
    "now = datetime.now(pytz.utc)  #tz Aware\n",
    "starttime = now - timedelta(hours=0, minutes=_AVERAGING_INTERVAL_MINUTES)\n",
    "logger(_LOG_DEBUG, \"Current time is {}\".format(now))\n",
    "logger(_LOG_DEBUG, \"Query timestamp will start at {}\".format(starttime))\n",
    "\n",
    "nodequery = \"SELECT * FROM kanji_node WHERE application_id={};\".format(_CATTLE_TROUGH_MONITOR)\n",
    "df = pd.read_sql(nodequery, conn)\n",
    "\n",
    "logger(_LOG_DEBUG, \"number of trough nodes {}\".format(len(df.index)))\n",
    "for ind in df.index:\n",
    "  ticketType = None\n",
    "  node_id = df['idnode'][ind]\n",
    "  nodename = df['name'][ind]\n",
    "  logger(_LOG_INFO, \"\\nAllTroughs processing for node {}\".format(nodename))\n",
    "  location_id = df['location_id'][ind]\n",
    "  eventquery = \"SELECT dval, eval FROM kanji_eventlog WHERE node_id={} AND sensortype_id=39 AND timestamp > '{}' ORDER BY timestamp desc;\".format(node_id, starttime)\n",
    "  logger(_LOG_DEBUG, eventquery)\n",
    "  df2 = pd.read_sql(eventquery, conn)\n",
    "  samplesize = len(df2.index)\n",
    "  logger(_LOG_DEBUG, \"samplesize {}\".format(samplesize))\n",
    "  wmaMean = 0.0\n",
    "  wmaSd = 0.0\n",
    "  divisor = 0 \n",
    "  for ind2 in df2.index:\n",
    "    logger(_LOG_INFO, \"{} {}\".format(float(df2['dval'][ind2]), float(df2['eval'][ind2])))\n",
    "    wmaMean += float(df2['dval'][ind2]) * (samplesize - ind2)\n",
    "    wmaSd   += float(df2['eval'][ind2]) * (samplesize - ind2)\n",
    "    divisor += (samplesize - ind2)    \n",
    "  wmaMean = wmaMean/divisor\n",
    "  wmaSd   = wmaSd/divisor\n",
    "  logger(_LOG_INFO, \"wmaMean={} wmaSd={}\".format(wmaMean, wmaSd))\n",
    "  if (wmaSd<= _MINIMUM_SD) or (wmaMean>_MAXIMUM_MEAN) or (wmaMean<_MINIMUM_MEAN):\n",
    "    logger(_LOG_INFO, \"wmaSd below critical value, possible failed sensor.\")\n",
    "    ticketType = BAD_FLUIDLEVEL_SENSOR\n",
    "    description = \"BAD FLUID LEVEL SENSOR. wmaMean={:5.2f} wmaSd={:5.2f}\".format(wmaMean, wmaSd)\n",
    "  elif wmaMean>=_THRESHOLD_WMAMEAN:\n",
    "    logger(_LOG_INFO, \"WATER LEVEL OK. wmaMean={:5.2f} wmaSd={:5.2f}\".format(wmaMean, wmaSd))    \n",
    "  else:\n",
    "    ticketType = LOW_WATER_LEVEL\n",
    "    description = \"LOW WATER LEVEL. wmaMean={:5.2f} wmaSd={:5.2f}\".format(wmaMean, wmaSd)   \n",
    "  if ticketType is not None:\n",
    "    #trigger an alert ONLY if the sensor is DRY'    \n",
    "    locationquery = \"SELECT location.idlocation, location.description, location.imageurl, \\\n",
    "                     slackchannel.idslackchannel, slackchannel.channelname, slackchannel.channelid, customer.slacktoken \\\n",
    "                     FROM kanji_location location \\\n",
    "                     JOIN kanji_customer customer ON location.customer_id=customer.idcustomer \\\n",
    "                     JOIN kanji_slackchannel slackchannel ON location.slackalertchannel_id=slackchannel.idslackchannel \\\n",
    "                     WHERE idlocation={}\".format(location_id)\n",
    "    df3 = pd.read_sql(locationquery, conn)\n",
    "    locationid = df3[\"idlocation\"][0]\n",
    "    locationimageurl = df3[\"imageurl\"][0]\n",
    "    logger(_LOG_DEBUG, locationimageurl)\n",
    "    locationdescription = df3[\"description\"][0]\n",
    "    _SLACK_TOKEN = df3[\"slacktoken\"][0]\n",
    "    \n",
    "    _SLACK_CHANNEL_NAME = df3[\"channelname\"][0]\n",
    "    _SLACK_CHANNEL_ID = df3[\"channelid\"][0]\n",
    "    _SLACK_CHANNEL_DBID = df3[\"idslackchannel\"][0]\n",
    "    \n",
    "    logger(_LOG_DEBUG, \"slackChannelName = {}\".format(_SLACK_CHANNEL_NAME))\n",
    "    logger(_LOG_DEBUG, \"slackChannelId   = {}\".format(_SLACK_CHANNEL_ID))\n",
    "    \n",
    "    logger(_LOG_DEBUG, \"locationdata\")\n",
    "    logger(_LOG_DEBUG, \"locationQuery={}\".format(locationquery))    \n",
    "    mentions = \" @Charlie, @Jared\"\n",
    "    #generate and Slack a new ticket ONLY if there is not a currently open ticket for this issue\n",
    "    openTicket = kt.ticketExists(conn, node_id, ticketType, [kt._OPEN_STATUS, kt._WORKING_STATUS])\n",
    "    if openTicket is None:\n",
    "      ticketid = kt.openticket(conn, node_id, locationid, description, 2, 3, ticketType, _SLACK_CHANNEL_DBID)\n",
    "      ts = kt.slackticket(nodename, locationdescription, description, mentions, 2, 3, locationimageurl, _SLACK_TOKEN, _SLACK_CHANNEL_NAME, ticketid, 0)\n",
    "      kt.updateTicket(conn, ticketid, ts)  \n",
    "      logger(_LOG_INFO, \"New ticket {} created for this issue.\".format(ticketid))\n",
    "    else:\n",
    "      logger(_LOG_INFO, \"There is an existing ticket #{} for this issue. Created at {}\".format(openTicket['idticket'][0], openTicket['opentimestamp'][0]))      \n",
    "  else:\n",
    "      logger(_LOG_INFO, \"No ticketable events for node {}\".format(nodename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KanjiProjects",
   "language": "python",
   "name": "kanjiprojects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
